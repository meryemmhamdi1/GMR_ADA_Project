{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training Model for Multiple Languages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 1402170/1402170 [05:25<00:00, 4310.65it/s]\n"
     ]
    }
   ],
   "source": [
    "# LOADING TOKENIZED REPRESENTATION\n",
    "import pandas as pd\n",
    "tokenized = pd.read_csv('../../Project_Backup/BigData/Unannotated_Representation/de/Unannotated_Representation1_sw.csv',encoding=\"ISO-8859-1\")\n",
    "tokenized1 = pd.read_csv('../../Project_Backup/BigData/Unannotated_Representation/de/Unannotated_Representation2_sw.csv',encoding=\"ISO-8859-1\")\n",
    "tokenized2 = pd.read_csv('../../Project_Backup/BigData/Unannotated_Representation/de/Unannotated_Representation3_sw.csv',encoding=\"ISO-8859-1\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "tokenized_lemma = list(tokenized['Tokenized Lemmatized'])+list(tokenized1['Tokenized Lemmatized'])+list(tokenized2['Tokenized Lemmatized'])\n",
    "tokenized_lemmatized_tweets = []\n",
    "for i in tqdm(range(0, len(tokenized_lemma))):\n",
    "    result = ast.literal_eval(tokenized_lemma[i])\n",
    "    tokenized_lemmatized_tweets.append(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training model...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2017-01-29 18:52:51,551 : INFO : collecting all words and their counts\n",
      "2017-01-29 18:52:51,644 : INFO : PROGRESS: at sentence #0, processed 0 words, keeping 0 word types\n",
      "2017-01-29 18:52:53,335 : INFO : PROGRESS: at sentence #10000, processed 105723 words, keeping 19975 word types\n",
      "2017-01-29 18:52:54,123 : INFO : PROGRESS: at sentence #20000, processed 210660 words, keeping 31855 word types\n",
      "2017-01-29 18:52:55,366 : INFO : PROGRESS: at sentence #30000, processed 316718 words, keeping 42311 word types\n",
      "2017-01-29 18:52:55,709 : INFO : PROGRESS: at sentence #40000, processed 428061 words, keeping 51131 word types\n",
      "2017-01-29 18:52:55,938 : INFO : PROGRESS: at sentence #50000, processed 524374 words, keeping 59802 word types\n",
      "2017-01-29 18:52:56,157 : INFO : PROGRESS: at sentence #60000, processed 614881 words, keeping 67187 word types\n",
      "2017-01-29 18:52:56,563 : INFO : PROGRESS: at sentence #70000, processed 703205 words, keeping 73611 word types\n",
      "2017-01-29 18:52:56,782 : INFO : PROGRESS: at sentence #80000, processed 786068 words, keeping 79612 word types\n",
      "2017-01-29 18:52:56,922 : INFO : PROGRESS: at sentence #90000, processed 871872 words, keeping 85891 word types\n",
      "2017-01-29 18:52:57,133 : INFO : PROGRESS: at sentence #100000, processed 958147 words, keeping 91446 word types\n",
      "2017-01-29 18:52:57,461 : INFO : PROGRESS: at sentence #110000, processed 1045560 words, keeping 97189 word types\n",
      "2017-01-29 18:52:57,950 : INFO : PROGRESS: at sentence #120000, processed 1135685 words, keeping 102879 word types\n",
      "2017-01-29 18:52:58,254 : INFO : PROGRESS: at sentence #130000, processed 1224664 words, keeping 108701 word types\n",
      "2017-01-29 18:52:58,535 : INFO : PROGRESS: at sentence #140000, processed 1314973 words, keeping 114428 word types\n",
      "2017-01-29 18:52:58,691 : INFO : PROGRESS: at sentence #150000, processed 1405147 words, keeping 120032 word types\n",
      "2017-01-29 18:52:58,979 : INFO : PROGRESS: at sentence #160000, processed 1498345 words, keeping 125496 word types\n",
      "2017-01-29 18:52:59,104 : INFO : PROGRESS: at sentence #170000, processed 1593333 words, keeping 130592 word types\n",
      "2017-01-29 18:52:59,198 : INFO : PROGRESS: at sentence #180000, processed 1686418 words, keeping 136068 word types\n",
      "2017-01-29 18:52:59,370 : INFO : PROGRESS: at sentence #190000, processed 1776491 words, keeping 141272 word types\n",
      "2017-01-29 18:52:59,573 : INFO : PROGRESS: at sentence #200000, processed 1866295 words, keeping 146367 word types\n",
      "2017-01-29 18:52:59,714 : INFO : PROGRESS: at sentence #210000, processed 1959028 words, keeping 151421 word types\n",
      "2017-01-29 18:52:59,839 : INFO : PROGRESS: at sentence #220000, processed 2050534 words, keeping 156396 word types\n",
      "2017-01-29 18:52:59,932 : INFO : PROGRESS: at sentence #230000, processed 2139865 words, keeping 161151 word types\n",
      "2017-01-29 18:53:00,023 : INFO : PROGRESS: at sentence #240000, processed 2226908 words, keeping 165813 word types\n",
      "2017-01-29 18:53:00,116 : INFO : PROGRESS: at sentence #250000, processed 2312552 words, keeping 170562 word types\n",
      "2017-01-29 18:53:00,194 : INFO : PROGRESS: at sentence #260000, processed 2400150 words, keeping 175294 word types\n",
      "2017-01-29 18:53:00,304 : INFO : PROGRESS: at sentence #270000, processed 2487439 words, keeping 180030 word types\n",
      "2017-01-29 18:53:00,366 : INFO : PROGRESS: at sentence #280000, processed 2575022 words, keeping 184431 word types\n",
      "2017-01-29 18:53:00,523 : INFO : PROGRESS: at sentence #290000, processed 2659671 words, keeping 189061 word types\n",
      "2017-01-29 18:53:00,616 : INFO : PROGRESS: at sentence #300000, processed 2742532 words, keeping 193552 word types\n",
      "2017-01-29 18:53:00,679 : INFO : PROGRESS: at sentence #310000, processed 2825888 words, keeping 197904 word types\n",
      "2017-01-29 18:53:00,741 : INFO : PROGRESS: at sentence #320000, processed 2908858 words, keeping 202158 word types\n",
      "2017-01-29 18:53:00,819 : INFO : PROGRESS: at sentence #330000, processed 2989259 words, keeping 206273 word types\n",
      "2017-01-29 18:53:00,866 : INFO : PROGRESS: at sentence #340000, processed 3073304 words, keeping 210266 word types\n",
      "2017-01-29 18:53:00,929 : INFO : PROGRESS: at sentence #350000, processed 3157502 words, keeping 214532 word types\n",
      "2017-01-29 18:53:00,984 : INFO : PROGRESS: at sentence #360000, processed 3239832 words, keeping 218695 word types\n",
      "2017-01-29 18:53:01,035 : INFO : PROGRESS: at sentence #370000, processed 3320434 words, keeping 222873 word types\n",
      "2017-01-29 18:53:01,098 : INFO : PROGRESS: at sentence #380000, processed 3403171 words, keeping 227071 word types\n",
      "2017-01-29 18:53:01,160 : INFO : PROGRESS: at sentence #390000, processed 3489152 words, keeping 231263 word types\n",
      "2017-01-29 18:53:01,207 : INFO : PROGRESS: at sentence #400000, processed 3574891 words, keeping 235500 word types\n",
      "2017-01-29 18:53:01,316 : INFO : PROGRESS: at sentence #410000, processed 3658893 words, keeping 239866 word types\n",
      "2017-01-29 18:53:01,363 : INFO : PROGRESS: at sentence #420000, processed 3742686 words, keeping 243920 word types\n",
      "2017-01-29 18:53:01,426 : INFO : PROGRESS: at sentence #430000, processed 3830226 words, keeping 248377 word types\n",
      "2017-01-29 18:53:01,488 : INFO : PROGRESS: at sentence #440000, processed 3916211 words, keeping 252662 word types\n",
      "2017-01-29 18:53:01,598 : INFO : PROGRESS: at sentence #450000, processed 4003919 words, keeping 256854 word types\n",
      "2017-01-29 18:53:01,660 : INFO : PROGRESS: at sentence #460000, processed 4090829 words, keeping 260851 word types\n",
      "2017-01-29 18:53:01,738 : INFO : PROGRESS: at sentence #470000, processed 4179498 words, keeping 264915 word types\n",
      "2017-01-29 18:53:02,008 : INFO : PROGRESS: at sentence #480000, processed 4267938 words, keeping 268934 word types\n",
      "2017-01-29 18:53:02,196 : INFO : PROGRESS: at sentence #490000, processed 4356730 words, keeping 273335 word types\n",
      "2017-01-29 18:53:02,305 : INFO : PROGRESS: at sentence #500000, processed 4441826 words, keeping 277546 word types\n",
      "2017-01-29 18:53:02,368 : INFO : PROGRESS: at sentence #510000, processed 4524869 words, keeping 281564 word types\n",
      "2017-01-29 18:53:02,462 : INFO : PROGRESS: at sentence #520000, processed 4614161 words, keeping 285515 word types\n",
      "2017-01-29 18:53:02,508 : INFO : PROGRESS: at sentence #530000, processed 4703633 words, keeping 289786 word types\n",
      "2017-01-29 18:53:02,602 : INFO : PROGRESS: at sentence #540000, processed 4794440 words, keeping 293783 word types\n",
      "2017-01-29 18:53:02,727 : INFO : PROGRESS: at sentence #550000, processed 4890413 words, keeping 297760 word types\n",
      "2017-01-29 18:53:02,852 : INFO : PROGRESS: at sentence #560000, processed 4982494 words, keeping 301492 word types\n",
      "2017-01-29 18:53:02,971 : INFO : PROGRESS: at sentence #570000, processed 5074302 words, keeping 305134 word types\n",
      "2017-01-29 18:53:03,063 : INFO : PROGRESS: at sentence #580000, processed 5165341 words, keeping 308851 word types\n",
      "2017-01-29 18:53:03,173 : INFO : PROGRESS: at sentence #590000, processed 5253742 words, keeping 312263 word types\n",
      "2017-01-29 18:53:03,423 : INFO : PROGRESS: at sentence #600000, processed 5345249 words, keeping 315954 word types\n",
      "2017-01-29 18:53:03,485 : INFO : PROGRESS: at sentence #610000, processed 5437736 words, keeping 319784 word types\n",
      "2017-01-29 18:53:03,548 : INFO : PROGRESS: at sentence #620000, processed 5529561 words, keeping 323409 word types\n",
      "2017-01-29 18:53:03,610 : INFO : PROGRESS: at sentence #630000, processed 5623193 words, keeping 327174 word types\n",
      "2017-01-29 18:53:03,688 : INFO : PROGRESS: at sentence #640000, processed 5715089 words, keeping 330878 word types\n",
      "2017-01-29 18:53:03,766 : INFO : PROGRESS: at sentence #650000, processed 5807058 words, keeping 334653 word types\n",
      "2017-01-29 18:53:03,876 : INFO : PROGRESS: at sentence #660000, processed 5897084 words, keeping 338354 word types\n",
      "2017-01-29 18:53:03,954 : INFO : PROGRESS: at sentence #670000, processed 5987332 words, keeping 342064 word types\n",
      "2017-01-29 18:53:04,011 : INFO : PROGRESS: at sentence #680000, processed 6071649 words, keeping 345533 word types\n",
      "2017-01-29 18:53:04,089 : INFO : PROGRESS: at sentence #690000, processed 6157815 words, keeping 349001 word types\n",
      "2017-01-29 18:53:04,183 : INFO : PROGRESS: at sentence #700000, processed 6246138 words, keeping 352344 word types\n",
      "2017-01-29 18:53:04,230 : INFO : PROGRESS: at sentence #710000, processed 6335498 words, keeping 355935 word types\n",
      "2017-01-29 18:53:04,339 : INFO : PROGRESS: at sentence #720000, processed 6424308 words, keeping 359442 word types\n",
      "2017-01-29 18:53:04,418 : INFO : PROGRESS: at sentence #730000, processed 6516323 words, keeping 362799 word types\n",
      "2017-01-29 18:53:04,480 : INFO : PROGRESS: at sentence #740000, processed 6605652 words, keeping 366368 word types\n",
      "2017-01-29 18:53:04,543 : INFO : PROGRESS: at sentence #750000, processed 6697676 words, keeping 369726 word types\n",
      "2017-01-29 18:53:04,621 : INFO : PROGRESS: at sentence #760000, processed 6791898 words, keeping 373183 word types\n",
      "2017-01-29 18:53:04,714 : INFO : PROGRESS: at sentence #770000, processed 6887958 words, keeping 376846 word types\n",
      "2017-01-29 18:53:04,783 : INFO : PROGRESS: at sentence #780000, processed 6983870 words, keeping 380352 word types\n",
      "2017-01-29 18:53:04,852 : INFO : PROGRESS: at sentence #790000, processed 7079979 words, keeping 383826 word types\n",
      "2017-01-29 18:53:04,927 : INFO : PROGRESS: at sentence #800000, processed 7174919 words, keeping 387444 word types\n",
      "2017-01-29 18:53:05,004 : INFO : PROGRESS: at sentence #810000, processed 7271998 words, keeping 391221 word types\n",
      "2017-01-29 18:53:05,089 : INFO : PROGRESS: at sentence #820000, processed 7368158 words, keeping 394991 word types\n",
      "2017-01-29 18:53:05,153 : INFO : PROGRESS: at sentence #830000, processed 7460112 words, keeping 398458 word types\n",
      "2017-01-29 18:53:05,243 : INFO : PROGRESS: at sentence #840000, processed 7552942 words, keeping 401909 word types\n",
      "2017-01-29 18:53:05,371 : INFO : PROGRESS: at sentence #850000, processed 7641003 words, keeping 405167 word types\n",
      "2017-01-29 18:53:05,466 : INFO : PROGRESS: at sentence #860000, processed 7736006 words, keeping 408785 word types\n",
      "2017-01-29 18:53:05,561 : INFO : PROGRESS: at sentence #870000, processed 7830604 words, keeping 412173 word types\n",
      "2017-01-29 18:53:05,636 : INFO : PROGRESS: at sentence #880000, processed 7928573 words, keeping 415846 word types\n",
      "2017-01-29 18:53:05,704 : INFO : PROGRESS: at sentence #890000, processed 8029062 words, keeping 419687 word types\n",
      "2017-01-29 18:53:05,778 : INFO : PROGRESS: at sentence #900000, processed 8128459 words, keeping 423361 word types\n",
      "2017-01-29 18:53:05,846 : INFO : PROGRESS: at sentence #910000, processed 8228950 words, keeping 427016 word types\n",
      "2017-01-29 18:53:05,927 : INFO : PROGRESS: at sentence #920000, processed 8327262 words, keeping 430735 word types\n",
      "2017-01-29 18:53:06,009 : INFO : PROGRESS: at sentence #930000, processed 8425505 words, keeping 434509 word types\n",
      "2017-01-29 18:53:06,075 : INFO : PROGRESS: at sentence #940000, processed 8522428 words, keeping 437843 word types\n",
      "2017-01-29 18:53:06,181 : INFO : PROGRESS: at sentence #950000, processed 8619864 words, keeping 441438 word types\n",
      "2017-01-29 18:53:06,271 : INFO : PROGRESS: at sentence #960000, processed 8715172 words, keeping 445041 word types\n",
      "2017-01-29 18:53:06,429 : INFO : PROGRESS: at sentence #970000, processed 8818017 words, keeping 448626 word types\n",
      "2017-01-29 18:53:06,515 : INFO : PROGRESS: at sentence #980000, processed 8915970 words, keeping 452051 word types\n",
      "2017-01-29 18:53:06,585 : INFO : PROGRESS: at sentence #990000, processed 9012177 words, keeping 455514 word types\n",
      "2017-01-29 18:53:06,650 : INFO : PROGRESS: at sentence #1000000, processed 9099370 words, keeping 458654 word types\n",
      "2017-01-29 18:53:06,714 : INFO : PROGRESS: at sentence #1010000, processed 9191969 words, keeping 461939 word types\n",
      "2017-01-29 18:53:06,776 : INFO : PROGRESS: at sentence #1020000, processed 9282200 words, keeping 464922 word types\n",
      "2017-01-29 18:53:06,842 : INFO : PROGRESS: at sentence #1030000, processed 9375661 words, keeping 468106 word types\n",
      "2017-01-29 18:53:06,909 : INFO : PROGRESS: at sentence #1040000, processed 9469251 words, keeping 471385 word types\n",
      "2017-01-29 18:53:07,018 : INFO : PROGRESS: at sentence #1050000, processed 9565627 words, keeping 474699 word types\n",
      "2017-01-29 18:53:07,092 : INFO : PROGRESS: at sentence #1060000, processed 9687097 words, keeping 476871 word types\n",
      "2017-01-29 18:53:07,180 : INFO : PROGRESS: at sentence #1070000, processed 9808786 words, keeping 478883 word types\n",
      "2017-01-29 18:53:07,365 : INFO : PROGRESS: at sentence #1080000, processed 9914600 words, keeping 481943 word types\n",
      "2017-01-29 18:53:07,465 : INFO : PROGRESS: at sentence #1090000, processed 10023991 words, keeping 484645 word types\n",
      "2017-01-29 18:53:07,567 : INFO : PROGRESS: at sentence #1100000, processed 10118109 words, keeping 487617 word types\n",
      "2017-01-29 18:53:07,654 : INFO : PROGRESS: at sentence #1110000, processed 10213080 words, keeping 490780 word types\n",
      "2017-01-29 18:53:07,735 : INFO : PROGRESS: at sentence #1120000, processed 10304656 words, keeping 493664 word types\n",
      "2017-01-29 18:53:07,837 : INFO : PROGRESS: at sentence #1130000, processed 10392165 words, keeping 496363 word types\n",
      "2017-01-29 18:53:07,920 : INFO : PROGRESS: at sentence #1140000, processed 10482755 words, keeping 499149 word types\n",
      "2017-01-29 18:53:08,028 : INFO : PROGRESS: at sentence #1150000, processed 10571815 words, keeping 501868 word types\n",
      "2017-01-29 18:53:08,125 : INFO : PROGRESS: at sentence #1160000, processed 10659305 words, keeping 504510 word types\n",
      "2017-01-29 18:53:08,253 : INFO : PROGRESS: at sentence #1170000, processed 10748713 words, keeping 507250 word types\n",
      "2017-01-29 18:53:08,424 : INFO : PROGRESS: at sentence #1180000, processed 10837625 words, keeping 509913 word types\n",
      "2017-01-29 18:53:08,563 : INFO : PROGRESS: at sentence #1190000, processed 10930457 words, keeping 512580 word types\n",
      "2017-01-29 18:53:08,663 : INFO : PROGRESS: at sentence #1200000, processed 11020656 words, keeping 516179 word types\n",
      "2017-01-29 18:53:08,777 : INFO : PROGRESS: at sentence #1210000, processed 11108184 words, keeping 520316 word types\n",
      "2017-01-29 18:53:08,884 : INFO : PROGRESS: at sentence #1220000, processed 11201612 words, keeping 523333 word types\n",
      "2017-01-29 18:53:08,996 : INFO : PROGRESS: at sentence #1230000, processed 11294068 words, keeping 526193 word types\n",
      "2017-01-29 18:53:09,102 : INFO : PROGRESS: at sentence #1240000, processed 11386959 words, keeping 529091 word types\n",
      "2017-01-29 18:53:09,187 : INFO : PROGRESS: at sentence #1250000, processed 11479393 words, keeping 531936 word types\n",
      "2017-01-29 18:53:11,559 : INFO : PROGRESS: at sentence #1260000, processed 11573456 words, keeping 534824 word types\n",
      "2017-01-29 18:53:11,649 : INFO : PROGRESS: at sentence #1270000, processed 11665756 words, keeping 538279 word types\n",
      "2017-01-29 18:53:11,729 : INFO : PROGRESS: at sentence #1280000, processed 11756957 words, keeping 541442 word types\n",
      "2017-01-29 18:53:11,801 : INFO : PROGRESS: at sentence #1290000, processed 11848255 words, keeping 544234 word types\n",
      "2017-01-29 18:53:11,869 : INFO : PROGRESS: at sentence #1300000, processed 11939010 words, keeping 547588 word types\n",
      "2017-01-29 18:53:11,934 : INFO : PROGRESS: at sentence #1310000, processed 12031994 words, keeping 550748 word types\n",
      "2017-01-29 18:53:11,996 : INFO : PROGRESS: at sentence #1320000, processed 12121551 words, keeping 553527 word types\n",
      "2017-01-29 18:53:12,058 : INFO : PROGRESS: at sentence #1330000, processed 12213035 words, keeping 556327 word types\n",
      "2017-01-29 18:53:12,144 : INFO : PROGRESS: at sentence #1340000, processed 12303001 words, keeping 559076 word types\n",
      "2017-01-29 18:53:12,211 : INFO : PROGRESS: at sentence #1350000, processed 12390638 words, keeping 561553 word types\n",
      "2017-01-29 18:53:12,357 : INFO : PROGRESS: at sentence #1360000, processed 12478811 words, keeping 564360 word types\n",
      "2017-01-29 18:53:12,442 : INFO : PROGRESS: at sentence #1370000, processed 12569410 words, keeping 567012 word types\n",
      "2017-01-29 18:53:12,519 : INFO : PROGRESS: at sentence #1380000, processed 12658357 words, keeping 569505 word types\n",
      "2017-01-29 18:53:12,588 : INFO : PROGRESS: at sentence #1390000, processed 12747467 words, keeping 572149 word types\n",
      "2017-01-29 18:53:12,648 : INFO : PROGRESS: at sentence #1400000, processed 12833950 words, keeping 574593 word types\n",
      "2017-01-29 18:53:12,673 : INFO : collected 575149 word types from a corpus of 12853594 raw words and 1402170 sentences\n",
      "2017-01-29 18:53:12,716 : INFO : Loading a fresh vocabulary\n",
      "2017-01-29 18:53:17,814 : INFO : min_count=1 retains 575149 unique words (100% of original 575149, drops 0)\n",
      "2017-01-29 18:53:17,816 : INFO : min_count=1 leaves 12853594 word corpus (100% of original 12853594, drops 0)\n",
      "2017-01-29 18:53:22,145 : INFO : deleting the raw counts dictionary of 575149 items\n",
      "2017-01-29 18:53:23,352 : INFO : sample=0.001 downsamples 48 most-common words\n",
      "2017-01-29 18:53:23,354 : INFO : downsampling leaves estimated 11353683 word corpus (88.3% of prior 12853594)\n",
      "2017-01-29 18:53:24,841 : INFO : estimated required memory for 575149 words and 300 dimensions: 1667932100 bytes\n",
      "2017-01-29 18:53:30,836 : INFO : resetting layer weights\n",
      "2017-01-29 18:53:43,605 : INFO : training model with 4 workers on 575149 vocabulary and 300 features, using sg=0 hs=0 sample=0.001 negative=5 window=10\n",
      "2017-01-29 18:53:43,607 : INFO : expecting 1402170 sentences, matching count from corpus used for vocabulary survey\n",
      "2017-01-29 18:53:52,680 : INFO : PROGRESS: at 0.01% examples, 3405 words/s, in_qsize 1, out_qsize 1\n",
      "2017-01-29 18:53:53,537 : INFO : PROGRESS: at 0.24% examples, 43567 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:53:54,605 : INFO : PROGRESS: at 0.48% examples, 67129 words/s, in_qsize 6, out_qsize 0\n",
      "2017-01-29 18:53:55,642 : INFO : PROGRESS: at 0.83% examples, 91766 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:53:56,718 : INFO : PROGRESS: at 0.99% examples, 90223 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:53:57,777 : INFO : PROGRESS: at 1.25% examples, 94961 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:53:58,825 : INFO : PROGRESS: at 1.66% examples, 108663 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:53:59,832 : INFO : PROGRESS: at 1.89% examples, 110997 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:00,891 : INFO : PROGRESS: at 2.22% examples, 117270 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:01,963 : INFO : PROGRESS: at 2.40% examples, 115626 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:54:02,987 : INFO : PROGRESS: at 2.62% examples, 116072 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:54:04,022 : INFO : PROGRESS: at 2.93% examples, 120083 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:05,125 : INFO : PROGRESS: at 3.31% examples, 125361 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:54:06,151 : INFO : PROGRESS: at 3.53% examples, 124556 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:07,255 : INFO : PROGRESS: at 3.74% examples, 123276 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:54:08,291 : INFO : PROGRESS: at 4.07% examples, 125950 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:09,338 : INFO : PROGRESS: at 4.20% examples, 122822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:12,004 : INFO : PROGRESS: at 4.48% examples, 114406 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:54:13,052 : INFO : PROGRESS: at 4.60% examples, 111909 words/s, in_qsize 6, out_qsize 3\n",
      "2017-01-29 18:54:14,053 : INFO : PROGRESS: at 4.62% examples, 107640 words/s, in_qsize 8, out_qsize 5\n",
      "2017-01-29 18:54:15,337 : INFO : PROGRESS: at 4.76% examples, 105012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:19,013 : INFO : PROGRESS: at 4.77% examples, 92049 words/s, in_qsize 8, out_qsize 4\n",
      "2017-01-29 18:54:24,827 : INFO : PROGRESS: at 4.79% examples, 76974 words/s, in_qsize 8, out_qsize 7\n",
      "2017-01-29 18:54:27,334 : INFO : PROGRESS: at 4.81% examples, 72056 words/s, in_qsize 8, out_qsize 9\n",
      "2017-01-29 18:54:28,991 : INFO : PROGRESS: at 4.83% examples, 69225 words/s, in_qsize 8, out_qsize 11\n",
      "2017-01-29 18:54:30,579 : INFO : PROGRESS: at 5.13% examples, 70464 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:54:31,676 : INFO : PROGRESS: at 5.33% examples, 70969 words/s, in_qsize 7, out_qsize 3\n",
      "2017-01-29 18:54:32,881 : INFO : PROGRESS: at 5.59% examples, 72293 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:33,931 : INFO : PROGRESS: at 5.92% examples, 74410 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:54:34,992 : INFO : PROGRESS: at 6.42% examples, 78794 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:54:36,176 : INFO : PROGRESS: at 6.61% examples, 78901 words/s, in_qsize 6, out_qsize 2\n",
      "2017-01-29 18:54:37,256 : INFO : PROGRESS: at 6.83% examples, 79729 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:38,264 : INFO : PROGRESS: at 7.07% examples, 80829 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:54:39,504 : INFO : PROGRESS: at 7.42% examples, 82581 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:54:40,653 : INFO : PROGRESS: at 7.53% examples, 81939 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:54:41,671 : INFO : PROGRESS: at 7.68% examples, 81877 words/s, in_qsize 8, out_qsize 3\n",
      "2017-01-29 18:54:44,248 : INFO : PROGRESS: at 7.79% examples, 79297 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:54:46,591 : INFO : PROGRESS: at 7.81% examples, 76173 words/s, in_qsize 4, out_qsize 4\n",
      "2017-01-29 18:54:47,859 : INFO : PROGRESS: at 7.82% examples, 74660 words/s, in_qsize 8, out_qsize 5\n",
      "2017-01-29 18:54:48,884 : INFO : PROGRESS: at 7.98% examples, 74862 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:54:49,921 : INFO : PROGRESS: at 8.18% examples, 75492 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:54:50,995 : INFO : PROGRESS: at 8.35% examples, 75762 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:52,109 : INFO : PROGRESS: at 8.47% examples, 75404 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:54,665 : INFO : PROGRESS: at 8.48% examples, 72565 words/s, in_qsize 7, out_qsize 6\n",
      "2017-01-29 18:54:55,847 : INFO : PROGRESS: at 8.65% examples, 72742 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:54:57,178 : INFO : PROGRESS: at 8.67% examples, 71434 words/s, in_qsize 6, out_qsize 6\n",
      "2017-01-29 18:54:58,307 : INFO : PROGRESS: at 8.68% examples, 70384 words/s, in_qsize 8, out_qsize 9\n",
      "2017-01-29 18:55:00,160 : INFO : PROGRESS: at 8.95% examples, 70673 words/s, in_qsize 6, out_qsize 2\n",
      "2017-01-29 18:55:01,194 : INFO : PROGRESS: at 9.02% examples, 70270 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:55:02,220 : INFO : PROGRESS: at 9.10% examples, 69887 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:55:03,220 : INFO : PROGRESS: at 9.18% examples, 69535 words/s, in_qsize 5, out_qsize 1\n",
      "2017-01-29 18:55:04,277 : INFO : PROGRESS: at 9.45% examples, 70574 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:05,414 : INFO : PROGRESS: at 9.69% examples, 71271 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:07,070 : INFO : PROGRESS: at 9.84% examples, 70774 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:08,076 : INFO : PROGRESS: at 9.86% examples, 69976 words/s, in_qsize 8, out_qsize 3\n",
      "2017-01-29 18:55:09,109 : INFO : PROGRESS: at 10.05% examples, 70405 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:10,320 : INFO : PROGRESS: at 10.26% examples, 70773 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:11,367 : INFO : PROGRESS: at 10.52% examples, 71713 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:12,467 : INFO : PROGRESS: at 10.75% examples, 72366 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:13,495 : INFO : PROGRESS: at 11.00% examples, 73169 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:14,585 : INFO : PROGRESS: at 11.28% examples, 74216 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:55:15,738 : INFO : PROGRESS: at 11.56% examples, 75193 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:16,745 : INFO : PROGRESS: at 11.94% examples, 76866 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:55:17,753 : INFO : PROGRESS: at 12.21% examples, 77701 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:18,812 : INFO : PROGRESS: at 12.49% examples, 78674 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:19,857 : INFO : PROGRESS: at 12.75% examples, 79536 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:20,984 : INFO : PROGRESS: at 13.03% examples, 80504 words/s, in_qsize 5, out_qsize 1\n",
      "2017-01-29 18:55:22,097 : INFO : PROGRESS: at 13.13% examples, 80207 words/s, in_qsize 5, out_qsize 1\n",
      "2017-01-29 18:55:23,340 : INFO : PROGRESS: at 13.15% examples, 79235 words/s, in_qsize 4, out_qsize 2\n",
      "2017-01-29 18:55:25,325 : INFO : PROGRESS: at 13.16% examples, 77678 words/s, in_qsize 1, out_qsize 6\n",
      "2017-01-29 18:55:27,311 : INFO : PROGRESS: at 13.18% examples, 76186 words/s, in_qsize 8, out_qsize 10\n",
      "2017-01-29 18:55:28,318 : INFO : PROGRESS: at 13.51% examples, 77473 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:29,323 : INFO : PROGRESS: at 13.86% examples, 78822 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:30,349 : INFO : PROGRESS: at 14.16% examples, 79777 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:31,352 : INFO : PROGRESS: at 14.46% examples, 80649 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:32,454 : INFO : PROGRESS: at 14.69% examples, 81080 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:34,397 : INFO : PROGRESS: at 14.89% examples, 80675 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:35,813 : INFO : PROGRESS: at 15.01% examples, 80257 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:36,843 : INFO : PROGRESS: at 15.23% examples, 80967 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:55:37,941 : INFO : PROGRESS: at 15.59% examples, 82277 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:55:39,035 : INFO : PROGRESS: at 15.88% examples, 82986 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:40,138 : INFO : PROGRESS: at 16.17% examples, 83594 words/s, in_qsize 8, out_qsize 3\n",
      "2017-01-29 18:55:41,167 : INFO : PROGRESS: at 16.60% examples, 84953 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:42,391 : INFO : PROGRESS: at 16.93% examples, 85656 words/s, in_qsize 6, out_qsize 3\n",
      "2017-01-29 18:55:43,412 : INFO : PROGRESS: at 17.30% examples, 86677 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:44,495 : INFO : PROGRESS: at 17.70% examples, 87849 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:55:45,601 : INFO : PROGRESS: at 18.00% examples, 88529 words/s, in_qsize 6, out_qsize 2\n",
      "2017-01-29 18:55:46,780 : INFO : PROGRESS: at 18.39% examples, 89521 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:55:48,138 : INFO : PROGRESS: at 18.55% examples, 89239 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:49,451 : INFO : PROGRESS: at 18.81% examples, 89512 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:50,452 : INFO : PROGRESS: at 19.13% examples, 90230 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:51,519 : INFO : PROGRESS: at 19.41% examples, 90671 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:52,601 : INFO : PROGRESS: at 19.56% examples, 90591 words/s, in_qsize 5, out_qsize 2\n",
      "2017-01-29 18:55:53,620 : INFO : PROGRESS: at 19.98% examples, 91702 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:54,623 : INFO : PROGRESS: at 20.51% examples, 93698 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:55,631 : INFO : PROGRESS: at 20.99% examples, 95185 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:56,676 : INFO : PROGRESS: at 21.54% examples, 96706 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:57,699 : INFO : PROGRESS: at 22.02% examples, 98009 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:55:58,725 : INFO : PROGRESS: at 22.65% examples, 100049 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:55:59,740 : INFO : PROGRESS: at 23.25% examples, 101855 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:00,766 : INFO : PROGRESS: at 23.87% examples, 103639 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:01,790 : INFO : PROGRESS: at 24.44% examples, 105119 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:02,808 : INFO : PROGRESS: at 25.03% examples, 106592 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:03,811 : INFO : PROGRESS: at 25.61% examples, 108056 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:04,833 : INFO : PROGRESS: at 26.23% examples, 109680 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:05,843 : INFO : PROGRESS: at 26.87% examples, 111479 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:06,880 : INFO : PROGRESS: at 27.56% examples, 113372 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:07,890 : INFO : PROGRESS: at 28.21% examples, 115240 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:08,929 : INFO : PROGRESS: at 28.76% examples, 116616 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:09,930 : INFO : PROGRESS: at 29.32% examples, 118052 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:10,929 : INFO : PROGRESS: at 29.97% examples, 119727 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:11,943 : INFO : PROGRESS: at 30.62% examples, 121436 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:12,941 : INFO : PROGRESS: at 31.25% examples, 123174 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:13,946 : INFO : PROGRESS: at 31.87% examples, 124904 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:15,005 : INFO : PROGRESS: at 32.57% examples, 126806 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:16,027 : INFO : PROGRESS: at 33.13% examples, 128299 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:17,042 : INFO : PROGRESS: at 33.72% examples, 129817 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:56:18,053 : INFO : PROGRESS: at 34.38% examples, 131560 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:56:19,054 : INFO : PROGRESS: at 35.04% examples, 133267 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:20,067 : INFO : PROGRESS: at 35.67% examples, 135093 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:21,086 : INFO : PROGRESS: at 36.34% examples, 136687 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:22,120 : INFO : PROGRESS: at 36.96% examples, 138000 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:23,127 : INFO : PROGRESS: at 37.53% examples, 139166 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:24,152 : INFO : PROGRESS: at 38.09% examples, 140349 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:25,168 : INFO : PROGRESS: at 38.66% examples, 141475 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:26,192 : INFO : PROGRESS: at 39.26% examples, 142690 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:27,200 : INFO : PROGRESS: at 39.93% examples, 144135 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:28,211 : INFO : PROGRESS: at 40.49% examples, 145480 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:29,244 : INFO : PROGRESS: at 41.13% examples, 146801 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:56:30,251 : INFO : PROGRESS: at 41.76% examples, 148032 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:31,264 : INFO : PROGRESS: at 42.29% examples, 148971 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:32,266 : INFO : PROGRESS: at 42.85% examples, 150012 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:33,285 : INFO : PROGRESS: at 43.54% examples, 151414 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:34,306 : INFO : PROGRESS: at 44.20% examples, 152632 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:35,308 : INFO : PROGRESS: at 44.92% examples, 153965 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:36,343 : INFO : PROGRESS: at 45.64% examples, 155252 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:37,348 : INFO : PROGRESS: at 46.32% examples, 156505 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:38,370 : INFO : PROGRESS: at 46.97% examples, 157666 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:39,389 : INFO : PROGRESS: at 47.61% examples, 158767 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:40,398 : INFO : PROGRESS: at 48.24% examples, 159960 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:41,418 : INFO : PROGRESS: at 48.87% examples, 161079 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:56:42,439 : INFO : PROGRESS: at 49.49% examples, 162180 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:43,449 : INFO : PROGRESS: at 50.19% examples, 163431 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:44,470 : INFO : PROGRESS: at 50.86% examples, 164654 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:45,478 : INFO : PROGRESS: at 51.45% examples, 165728 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:46,478 : INFO : PROGRESS: at 52.05% examples, 166747 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:47,478 : INFO : PROGRESS: at 52.67% examples, 167906 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:56:48,495 : INFO : PROGRESS: at 53.31% examples, 169137 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:49,512 : INFO : PROGRESS: at 53.90% examples, 170197 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:50,527 : INFO : PROGRESS: at 54.59% examples, 171450 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:51,540 : INFO : PROGRESS: at 55.22% examples, 172638 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:52,554 : INFO : PROGRESS: at 55.77% examples, 173560 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:53,572 : INFO : PROGRESS: at 56.40% examples, 174513 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:54,608 : INFO : PROGRESS: at 56.99% examples, 175284 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:56:55,642 : INFO : PROGRESS: at 57.69% examples, 176443 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:56,674 : INFO : PROGRESS: at 58.37% examples, 177539 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:57,697 : INFO : PROGRESS: at 59.03% examples, 178544 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:58,735 : INFO : PROGRESS: at 59.69% examples, 179476 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:56:59,751 : INFO : PROGRESS: at 60.23% examples, 180187 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:00,758 : INFO : PROGRESS: at 60.76% examples, 181021 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:01,762 : INFO : PROGRESS: at 61.42% examples, 181920 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:02,772 : INFO : PROGRESS: at 62.11% examples, 182943 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:03,780 : INFO : PROGRESS: at 62.74% examples, 183865 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:04,793 : INFO : PROGRESS: at 63.42% examples, 184863 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:05,843 : INFO : PROGRESS: at 64.04% examples, 185593 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:06,874 : INFO : PROGRESS: at 64.70% examples, 186334 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:07,910 : INFO : PROGRESS: at 65.42% examples, 187250 words/s, in_qsize 8, out_qsize 2\n",
      "2017-01-29 18:57:08,932 : INFO : PROGRESS: at 66.11% examples, 188124 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:09,957 : INFO : PROGRESS: at 66.78% examples, 188988 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:10,970 : INFO : PROGRESS: at 67.40% examples, 189720 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:11,991 : INFO : PROGRESS: at 67.99% examples, 190431 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:12,995 : INFO : PROGRESS: at 68.56% examples, 191062 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:14,062 : INFO : PROGRESS: at 69.11% examples, 191627 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:15,065 : INFO : PROGRESS: at 69.79% examples, 192504 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:16,071 : INFO : PROGRESS: at 70.44% examples, 193325 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:17,080 : INFO : PROGRESS: at 71.11% examples, 194264 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:18,097 : INFO : PROGRESS: at 71.72% examples, 195059 words/s, in_qsize 6, out_qsize 2\n",
      "2017-01-29 18:57:19,139 : INFO : PROGRESS: at 72.34% examples, 195784 words/s, in_qsize 6, out_qsize 2\n",
      "2017-01-29 18:57:20,161 : INFO : PROGRESS: at 72.84% examples, 196310 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:21,232 : INFO : PROGRESS: at 73.36% examples, 196826 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:22,242 : INFO : PROGRESS: at 73.97% examples, 197639 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:23,245 : INFO : PROGRESS: at 74.62% examples, 198455 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:57:24,259 : INFO : PROGRESS: at 75.25% examples, 199362 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:25,285 : INFO : PROGRESS: at 75.86% examples, 200140 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:26,309 : INFO : PROGRESS: at 76.48% examples, 200779 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:27,312 : INFO : PROGRESS: at 77.08% examples, 201381 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:28,329 : INFO : PROGRESS: at 77.72% examples, 202098 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:57:29,371 : INFO : PROGRESS: at 78.42% examples, 202941 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:30,375 : INFO : PROGRESS: at 79.11% examples, 203778 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:31,398 : INFO : PROGRESS: at 79.77% examples, 204469 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:32,436 : INFO : PROGRESS: at 80.40% examples, 205252 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:33,468 : INFO : PROGRESS: at 80.92% examples, 205717 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:34,478 : INFO : PROGRESS: at 81.52% examples, 206210 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:35,535 : INFO : PROGRESS: at 82.14% examples, 206777 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:36,557 : INFO : PROGRESS: at 82.71% examples, 207292 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:57:37,570 : INFO : PROGRESS: at 83.29% examples, 207807 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:38,587 : INFO : PROGRESS: at 83.85% examples, 208204 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:57:39,609 : INFO : PROGRESS: at 84.37% examples, 208473 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:57:40,654 : INFO : PROGRESS: at 84.88% examples, 208687 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:41,663 : INFO : PROGRESS: at 85.32% examples, 208740 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:42,673 : INFO : PROGRESS: at 85.82% examples, 208980 words/s, in_qsize 8, out_qsize 2\n",
      "2017-01-29 18:57:43,702 : INFO : PROGRESS: at 86.35% examples, 209280 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:44,734 : INFO : PROGRESS: at 86.90% examples, 209650 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:45,758 : INFO : PROGRESS: at 87.46% examples, 210024 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:46,774 : INFO : PROGRESS: at 88.00% examples, 210435 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:47,791 : INFO : PROGRESS: at 88.49% examples, 210693 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:48,815 : INFO : PROGRESS: at 88.97% examples, 210940 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:49,838 : INFO : PROGRESS: at 89.42% examples, 211113 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:50,849 : INFO : PROGRESS: at 89.96% examples, 211441 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:51,856 : INFO : PROGRESS: at 90.52% examples, 211841 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:57:52,859 : INFO : PROGRESS: at 91.00% examples, 212130 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:53,868 : INFO : PROGRESS: at 91.51% examples, 212487 words/s, in_qsize 6, out_qsize 1\n",
      "2017-01-29 18:57:54,896 : INFO : PROGRESS: at 92.03% examples, 212829 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:55,905 : INFO : PROGRESS: at 92.48% examples, 213038 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:56,927 : INFO : PROGRESS: at 92.98% examples, 213414 words/s, in_qsize 8, out_qsize 1\n",
      "2017-01-29 18:57:57,932 : INFO : PROGRESS: at 93.55% examples, 213942 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:58,946 : INFO : PROGRESS: at 94.15% examples, 214524 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:57:59,955 : INFO : PROGRESS: at 94.81% examples, 215150 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:58:00,970 : INFO : PROGRESS: at 95.41% examples, 215846 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:58:01,998 : INFO : PROGRESS: at 96.02% examples, 216381 words/s, in_qsize 8, out_qsize 0\n",
      "2017-01-29 18:58:03,002 : INFO : PROGRESS: at 96.66% examples, 216910 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:58:04,007 : INFO : PROGRESS: at 97.32% examples, 217503 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:58:05,041 : INFO : PROGRESS: at 97.97% examples, 218067 words/s, in_qsize 7, out_qsize 1\n",
      "2017-01-29 18:58:06,088 : INFO : PROGRESS: at 98.62% examples, 218621 words/s, in_qsize 7, out_qsize 0\n",
      "2017-01-29 18:58:07,109 : INFO : PROGRESS: at 99.30% examples, 219226 words/s, in_qsize 8, out_qsize 2\n",
      "2017-01-29 18:58:08,198 : INFO : PROGRESS: at 99.96% examples, 219704 words/s, in_qsize 2, out_qsize 3\n",
      "2017-01-29 18:58:08,203 : INFO : worker thread finished; awaiting finish of 3 more threads\n",
      "2017-01-29 18:58:08,295 : INFO : worker thread finished; awaiting finish of 2 more threads\n",
      "2017-01-29 18:58:08,297 : INFO : worker thread finished; awaiting finish of 1 more threads\n",
      "2017-01-29 18:58:08,299 : INFO : worker thread finished; awaiting finish of 0 more threads\n",
      "2017-01-29 18:58:08,300 : INFO : training on 64267970 raw words (56767091 effective words) took 258.4s, 219704 effective words/s\n",
      "2017-01-29 18:58:10,793 : INFO : precomputing L2-norms of word weight vectors\n",
      "2017-01-29 18:58:18,022 : INFO : saving Word2Vec object under ../../Project_Backup/BigData/Models/whole_de_model, separately None\n",
      "2017-01-29 18:58:19,417 : INFO : storing np array 'syn0' to ../../Project_Backup/BigData/Models/whole_de_model.wv.syn0.npy\n",
      "2017-01-29 18:58:36,600 : INFO : not storing attribute cum_table\n",
      "2017-01-29 18:58:36,741 : INFO : storing np array 'syn1neg' to ../../Project_Backup/BigData/Models/whole_de_model.syn1neg.npy\n",
      "2017-01-29 18:58:50,449 : INFO : not storing attribute syn0norm\n",
      "2017-01-29 19:01:55,715 : INFO : saved ../../Project_Backup/BigData/Models/whole_de_model\n"
     ]
    }
   ],
   "source": [
    "# PARAMETERS TO BE TUNED:\n",
    "\n",
    "# Word vector dimensionality                      \n",
    "# Minimum word count                        \n",
    "# Number of threads to run in parallel\n",
    "# Context window size                                                                                    \n",
    "# Downsample setting for frequent words\n",
    "\n",
    "import logging\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s',\\\n",
    "    level=logging.INFO)\n",
    "\n",
    "# Set values for various parameters\n",
    "num_features = 300    # Word vector dimensionality\n",
    "min_word_count = 1  # Minimum word count\n",
    "num_workers = 4       # Number of threads to run in parallel\n",
    "context = 10          # Context window size\n",
    "downsampling = 1e-3   # Downsample setting for frequent words\n",
    "\n",
    "# Initialize and train the model (this will take some time)\n",
    "from gensim.models import word2vec\n",
    "print (\"Training model...\")\n",
    "model = word2vec.Word2Vec(tokenized_lemmatized_tweets, workers=num_workers,\n",
    "            size=num_features, min_count = min_word_count,\n",
    "            window = context, sample = downsampling)\n",
    "\n",
    "# If you don't plan to train the model any further, calling\n",
    "# init_sims will make the model much more memory-efficient.\n",
    "model.init_sims(replace=True)\n",
    "\n",
    "# It can be helpful to create a meaningful model name and\n",
    "# save the model for later use. You can load it later using Word2Vec.load()\n",
    "model_name = \"../../Project_Backup/BigData/Models/whole_de_model\"\n",
    "model.save(model_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from EmotionAnalysis.SentSemanticModule import *\n",
    "from EmotionAnalysis.SentTweetModule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"['hb']\""
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "tokenized = pd.read_csv('../../Project_Backup/BigData/Unannotated_Representation/tr/Unannotated_Representation1_sw.csv',encoding=\"ISO-8859-1\")\n",
    "\n",
    "from tqdm import tqdm\n",
    "import ast\n",
    "\n",
    "nava_repr = list(tokenized['Nava without Stop Words'])\n",
    "nava_repr[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert nava tweets\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 331035/331035 [00:09<00:00, 36335.72it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "['hb']"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print (\"Convert nava tweets\")\n",
    "# Convert nava_tweets \n",
    "nava_tweets = []\n",
    "for i in tqdm(range(0, len(nava_repr))):\n",
    "    result = ast.literal_eval(nava_repr[i])\n",
    "    nava_tweets.append(result)\n",
    "    #nava_tweets.append(nava_repr[i][1:len(nava_repr[i])-1].split(', '))\n",
    "nava_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Lexicon\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "print (\"Loading Lexicon\")\n",
    "with open('NRCLexicon/turkish_lexicon.pickle', 'rb') as handle:\n",
    "    lexicon_dict = pickle.load(handle)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "representative_set = []\n",
    "for i in range(0,10):\n",
    "    representative_set_sub = []\n",
    "    for word in lexicon_dict.keys():\n",
    "        if lexicon_dict[word][i] == 1: \n",
    "            representative_set_sub.append(word)\n",
    "    representative_set.append(representative_set_sub)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon_df = pd.DataFrame()\n",
    "lexicon_df[0] = representative_set[0]\n",
    "for i in range(1,10):\n",
    "    df = pd.DataFrame()\n",
    "    df[i] = representative_set[i]\n",
    "    lexicon_df= pd.concat([lexicon_df,df],ignore_index=True,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>kayıtsızlık</td>\n",
       "      <td>forewarned</td>\n",
       "      <td>kayıtsızlık</td>\n",
       "      <td>kayıtsızlık</td>\n",
       "      <td>faydalı</td>\n",
       "      <td>kayıtsızlık</td>\n",
       "      <td>üretici</td>\n",
       "      <td>kayıtsızlık</td>\n",
       "      <td>ortaya çıkarmak</td>\n",
       "      <td>haysiyet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>aptallık</td>\n",
       "      <td>özgürlük</td>\n",
       "      <td>sapık</td>\n",
       "      <td>Alarm</td>\n",
       "      <td>yeşil</td>\n",
       "      <td>zoraki</td>\n",
       "      <td>haysiyet</td>\n",
       "      <td>aptallık</td>\n",
       "      <td>mistik</td>\n",
       "      <td>dayanak noktası</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tütsü</td>\n",
       "      <td>macera</td>\n",
       "      <td>aptallık</td>\n",
       "      <td>hoşlanmama</td>\n",
       "      <td>özgürlük</td>\n",
       "      <td>sahipsiz</td>\n",
       "      <td>dayanak noktası</td>\n",
       "      <td>hariç</td>\n",
       "      <td>Alarm</td>\n",
       "      <td>faydalı</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hoşlanmama</td>\n",
       "      <td>far</td>\n",
       "      <td>hoşlanmama</td>\n",
       "      <td>şanssızlık</td>\n",
       "      <td>muzaffer</td>\n",
       "      <td>meme</td>\n",
       "      <td>faydalı</td>\n",
       "      <td>körü körüne</td>\n",
       "      <td>özgürlük</td>\n",
       "      <td>yeşil</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>kovulma</td>\n",
       "      <td>tükenme</td>\n",
       "      <td>kovulma</td>\n",
       "      <td>kovulma</td>\n",
       "      <td>mezuniyet</td>\n",
       "      <td>sakınca</td>\n",
       "      <td>yeşil</td>\n",
       "      <td>apse</td>\n",
       "      <td>dava</td>\n",
       "      <td>sade</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>öfkeli</td>\n",
       "      <td>mezuniyet</td>\n",
       "      <td>kolera</td>\n",
       "      <td>pus</td>\n",
       "      <td>yürekli</td>\n",
       "      <td>sapık</td>\n",
       "      <td>şövalyelik</td>\n",
       "      <td>kasvetli</td>\n",
       "      <td>mezuniyet</td>\n",
       "      <td>kozmopolit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>günah</td>\n",
       "      <td>piyango</td>\n",
       "      <td>çürüme</td>\n",
       "      <td>kolera</td>\n",
       "      <td>maaş</td>\n",
       "      <td>anayasaya aykırı</td>\n",
       "      <td>kozmopolit</td>\n",
       "      <td>kabul edilemez</td>\n",
       "      <td>hırsız</td>\n",
       "      <td>bayım</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>antitez</td>\n",
       "      <td>Komşuluk</td>\n",
       "      <td>saygısız</td>\n",
       "      <td>forewarned</td>\n",
       "      <td>tutkulu</td>\n",
       "      <td>yama</td>\n",
       "      <td>Bilişsel</td>\n",
       "      <td>şanssızlık</td>\n",
       "      <td>kararsız</td>\n",
       "      <td>sıkılık</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>dikkatsizlik</td>\n",
       "      <td>izlemek</td>\n",
       "      <td>dava</td>\n",
       "      <td>çürüme</td>\n",
       "      <td>çikolata</td>\n",
       "      <td>karartmak</td>\n",
       "      <td>ağırbaşlı</td>\n",
       "      <td>kovulma</td>\n",
       "      <td>kilitlenme</td>\n",
       "      <td>özgürlük</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>saygısız</td>\n",
       "      <td>hemen</td>\n",
       "      <td>kürtaj</td>\n",
       "      <td>saygısız</td>\n",
       "      <td>canlanma</td>\n",
       "      <td>aptallık</td>\n",
       "      <td>temiz</td>\n",
       "      <td>düşmek</td>\n",
       "      <td>pop</td>\n",
       "      <td>holding</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>dava</td>\n",
       "      <td>sabır</td>\n",
       "      <td>porno</td>\n",
       "      <td>aşma</td>\n",
       "      <td>mübarek</td>\n",
       "      <td>maruz</td>\n",
       "      <td>telafi edici</td>\n",
       "      <td>kitabe</td>\n",
       "      <td>sarsıntı</td>\n",
       "      <td>mütevazi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>reddediyoruz</td>\n",
       "      <td>maaş</td>\n",
       "      <td>kabızlık</td>\n",
       "      <td>dava</td>\n",
       "      <td>gıdıklamak</td>\n",
       "      <td>hariç</td>\n",
       "      <td>bayım</td>\n",
       "      <td>kolera</td>\n",
       "      <td>kaybetmek</td>\n",
       "      <td>iman</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>soymak</td>\n",
       "      <td>analist</td>\n",
       "      <td>oğul</td>\n",
       "      <td>eksik</td>\n",
       "      <td>aloha</td>\n",
       "      <td>körü körüne</td>\n",
       "      <td>sıkılık</td>\n",
       "      <td>çürüme</td>\n",
       "      <td>gıdıklamak</td>\n",
       "      <td>gösteri</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>tepki</td>\n",
       "      <td>tutkulu</td>\n",
       "      <td>reddediyoruz</td>\n",
       "      <td>kürtaj</td>\n",
       "      <td>Gökler</td>\n",
       "      <td>Alarm</td>\n",
       "      <td>atlet</td>\n",
       "      <td>saygısız</td>\n",
       "      <td>büyüklük</td>\n",
       "      <td>kooperatif</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>itiraz</td>\n",
       "      <td>çikolata</td>\n",
       "      <td>soymak</td>\n",
       "      <td>ölüme mahkum</td>\n",
       "      <td>özgürleşme</td>\n",
       "      <td>apse</td>\n",
       "      <td>eleştiri</td>\n",
       "      <td>dava</td>\n",
       "      <td>mucize</td>\n",
       "      <td>yuva</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>hırsız</td>\n",
       "      <td>kramp</td>\n",
       "      <td>sakar</td>\n",
       "      <td>soymak</td>\n",
       "      <td>Bulunan</td>\n",
       "      <td>tütsü</td>\n",
       "      <td>özgürlük</td>\n",
       "      <td>eksik</td>\n",
       "      <td>istemeden</td>\n",
       "      <td>reddediyoruz</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>nefret</td>\n",
       "      <td>netice</td>\n",
       "      <td>hırsız</td>\n",
       "      <td>kartuş</td>\n",
       "      <td>tatil</td>\n",
       "      <td>hoşlanmama</td>\n",
       "      <td>macera</td>\n",
       "      <td>kürtaj</td>\n",
       "      <td>hava saldırısı</td>\n",
       "      <td>kayıt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>sürtünme</td>\n",
       "      <td>canlanma</td>\n",
       "      <td>iki yüzlü</td>\n",
       "      <td>mezuniyet</td>\n",
       "      <td>armoni</td>\n",
       "      <td>yetki devri</td>\n",
       "      <td>mütevazi</td>\n",
       "      <td>ölüme mahkum</td>\n",
       "      <td>oynak</td>\n",
       "      <td>mezuniyet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>kirpik</td>\n",
       "      <td>gıdıklamak</td>\n",
       "      <td>şekil bozukluğu</td>\n",
       "      <td>tepki</td>\n",
       "      <td>otantik</td>\n",
       "      <td>kasvetli</td>\n",
       "      <td>kooperatif</td>\n",
       "      <td>soymak</td>\n",
       "      <td>flört</td>\n",
       "      <td>yürekli</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>iblis</td>\n",
       "      <td>aloha</td>\n",
       "      <td>ilmihal</td>\n",
       "      <td>hırsız</td>\n",
       "      <td>büyüklük</td>\n",
       "      <td>sade</td>\n",
       "      <td>tanıtım</td>\n",
       "      <td>tükenme</td>\n",
       "      <td>susuzluk</td>\n",
       "      <td>bütünlük</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>dökümleri</td>\n",
       "      <td>özgürleşme</td>\n",
       "      <td>şarlatan</td>\n",
       "      <td>polis</td>\n",
       "      <td>torunlar</td>\n",
       "      <td>kabul edilemez</td>\n",
       "      <td>muzaffer</td>\n",
       "      <td>hırsız</td>\n",
       "      <td>peri</td>\n",
       "      <td>polis</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>boşa</td>\n",
       "      <td>ulaşılabilir</td>\n",
       "      <td>çukurluğu</td>\n",
       "      <td>şekil bozukluğu</td>\n",
       "      <td>güzelleştirmek</td>\n",
       "      <td>şanssızlık</td>\n",
       "      <td>nimet</td>\n",
       "      <td>demirleme</td>\n",
       "      <td>alışveriş</td>\n",
       "      <td>kanıt</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>eşitsizlik</td>\n",
       "      <td>astrolog</td>\n",
       "      <td>kontamine</td>\n",
       "      <td>hakimiyet</td>\n",
       "      <td>gönüllü</td>\n",
       "      <td>kovulma</td>\n",
       "      <td>örgütlü</td>\n",
       "      <td>şekil bozukluğu</td>\n",
       "      <td>tamamlayıcısı</td>\n",
       "      <td>dayanma gücü</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>ızdırap</td>\n",
       "      <td>tatil</td>\n",
       "      <td>iblis</td>\n",
       "      <td>kararsız</td>\n",
       "      <td>mucize</td>\n",
       "      <td>öfkeli</td>\n",
       "      <td>kaya</td>\n",
       "      <td>çukurluğu</td>\n",
       "      <td>uyardı</td>\n",
       "      <td>masum</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>ayıp</td>\n",
       "      <td>torunlar</td>\n",
       "      <td>boşa</td>\n",
       "      <td>izlemek</td>\n",
       "      <td>vefa</td>\n",
       "      <td>düşmek</td>\n",
       "      <td>mezuniyet</td>\n",
       "      <td>iblis</td>\n",
       "      <td>coşku</td>\n",
       "      <td>hakimiyet</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>kaybetmek</td>\n",
       "      <td>şarta</td>\n",
       "      <td>organik gübre</td>\n",
       "      <td>tugay</td>\n",
       "      <td>kalkınan</td>\n",
       "      <td>günah</td>\n",
       "      <td>yorumcu</td>\n",
       "      <td>dökümleri</td>\n",
       "      <td>sırıtış</td>\n",
       "      <td>at</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>kapmak</td>\n",
       "      <td>gönüllü</td>\n",
       "      <td>ayıp</td>\n",
       "      <td>çukurluğu</td>\n",
       "      <td>favori</td>\n",
       "      <td>pus</td>\n",
       "      <td>yürekli</td>\n",
       "      <td>eşitsizlik</td>\n",
       "      <td>akrep</td>\n",
       "      <td>sabır</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>diken</td>\n",
       "      <td>mucize</td>\n",
       "      <td>ri</td>\n",
       "      <td>kirpik</td>\n",
       "      <td>Sevgilim</td>\n",
       "      <td>antitez</td>\n",
       "      <td>demirleme</td>\n",
       "      <td>ızdırap</td>\n",
       "      <td>çile</td>\n",
       "      <td>maaş</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>hükmetmek</td>\n",
       "      <td>kalkınan</td>\n",
       "      <td>kaybetmek</td>\n",
       "      <td>iblis</td>\n",
       "      <td>oynak</td>\n",
       "      <td>kolera</td>\n",
       "      <td>bütünlük</td>\n",
       "      <td>kilitlenme</td>\n",
       "      <td>nimetler</td>\n",
       "      <td>analist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>sahtekâr</td>\n",
       "      <td>köpek yavrusu</td>\n",
       "      <td>atık</td>\n",
       "      <td>dikkatlice</td>\n",
       "      <td>flört</td>\n",
       "      <td>forewarned</td>\n",
       "      <td>dayanma gücü</td>\n",
       "      <td>ağrıyan</td>\n",
       "      <td>hoş</td>\n",
       "      <td>tutkulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1593</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>adaletsizlik</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1594</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bitkin</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1595</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kıpırdamak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>karmakarışık</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1597</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>dikkat dağıtıcı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1598</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>inkâr</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1599</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kamçılamak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1600</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>tezat</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1601</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>durgunluk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1602</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>gecikme</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1603</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>bağnaz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1604</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>korkmuş</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1605</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kurban</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kandırmak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1607</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>hırsızlık</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1608</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>modası geçmiş</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1609</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Ruh</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1610</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>yaya</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1611</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>ağlamak</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1612</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kurtçuk</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1613</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>emmek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1614</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>drenaj</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1615</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>acı çektirmek</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1616</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>kesilmiş</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1617</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>düzenbaz</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1618</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Çürük</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1619</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>boykot</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1620</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>imha</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1621</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Güvenlik açığı</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1622</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>pısırık</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1623 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 0              1                2                3  \\\n",
       "0      kayıtsızlık     forewarned      kayıtsızlık      kayıtsızlık   \n",
       "1         aptallık       özgürlük            sapık            Alarm   \n",
       "2            tütsü         macera         aptallık       hoşlanmama   \n",
       "3       hoşlanmama            far       hoşlanmama       şanssızlık   \n",
       "4          kovulma        tükenme          kovulma          kovulma   \n",
       "5           öfkeli      mezuniyet           kolera              pus   \n",
       "6            günah        piyango           çürüme           kolera   \n",
       "7          antitez       Komşuluk         saygısız       forewarned   \n",
       "8     dikkatsizlik        izlemek             dava           çürüme   \n",
       "9         saygısız          hemen           kürtaj         saygısız   \n",
       "10            dava          sabır            porno             aşma   \n",
       "11    reddediyoruz           maaş         kabızlık             dava   \n",
       "12          soymak        analist             oğul            eksik   \n",
       "13           tepki        tutkulu     reddediyoruz           kürtaj   \n",
       "14          itiraz       çikolata           soymak     ölüme mahkum   \n",
       "15          hırsız          kramp            sakar           soymak   \n",
       "16          nefret         netice           hırsız           kartuş   \n",
       "17        sürtünme       canlanma        iki yüzlü        mezuniyet   \n",
       "18          kirpik     gıdıklamak  şekil bozukluğu            tepki   \n",
       "19           iblis          aloha          ilmihal           hırsız   \n",
       "20       dökümleri     özgürleşme         şarlatan            polis   \n",
       "21            boşa   ulaşılabilir        çukurluğu  şekil bozukluğu   \n",
       "22      eşitsizlik       astrolog        kontamine        hakimiyet   \n",
       "23         ızdırap          tatil            iblis         kararsız   \n",
       "24            ayıp       torunlar             boşa          izlemek   \n",
       "25       kaybetmek          şarta    organik gübre            tugay   \n",
       "26          kapmak        gönüllü             ayıp        çukurluğu   \n",
       "27           diken         mucize               ri           kirpik   \n",
       "28       hükmetmek       kalkınan        kaybetmek            iblis   \n",
       "29        sahtekâr  köpek yavrusu             atık       dikkatlice   \n",
       "...            ...            ...              ...              ...   \n",
       "1593           NaN            NaN              NaN              NaN   \n",
       "1594           NaN            NaN              NaN              NaN   \n",
       "1595           NaN            NaN              NaN              NaN   \n",
       "1596           NaN            NaN              NaN              NaN   \n",
       "1597           NaN            NaN              NaN              NaN   \n",
       "1598           NaN            NaN              NaN              NaN   \n",
       "1599           NaN            NaN              NaN              NaN   \n",
       "1600           NaN            NaN              NaN              NaN   \n",
       "1601           NaN            NaN              NaN              NaN   \n",
       "1602           NaN            NaN              NaN              NaN   \n",
       "1603           NaN            NaN              NaN              NaN   \n",
       "1604           NaN            NaN              NaN              NaN   \n",
       "1605           NaN            NaN              NaN              NaN   \n",
       "1606           NaN            NaN              NaN              NaN   \n",
       "1607           NaN            NaN              NaN              NaN   \n",
       "1608           NaN            NaN              NaN              NaN   \n",
       "1609           NaN            NaN              NaN              NaN   \n",
       "1610           NaN            NaN              NaN              NaN   \n",
       "1611           NaN            NaN              NaN              NaN   \n",
       "1612           NaN            NaN              NaN              NaN   \n",
       "1613           NaN            NaN              NaN              NaN   \n",
       "1614           NaN            NaN              NaN              NaN   \n",
       "1615           NaN            NaN              NaN              NaN   \n",
       "1616           NaN            NaN              NaN              NaN   \n",
       "1617           NaN            NaN              NaN              NaN   \n",
       "1618           NaN            NaN              NaN              NaN   \n",
       "1619           NaN            NaN              NaN              NaN   \n",
       "1620           NaN            NaN              NaN              NaN   \n",
       "1621           NaN            NaN              NaN              NaN   \n",
       "1622           NaN            NaN              NaN              NaN   \n",
       "\n",
       "                   4                 5                6                7  \\\n",
       "0            faydalı       kayıtsızlık          üretici      kayıtsızlık   \n",
       "1              yeşil            zoraki         haysiyet         aptallık   \n",
       "2           özgürlük          sahipsiz  dayanak noktası            hariç   \n",
       "3           muzaffer              meme          faydalı      körü körüne   \n",
       "4          mezuniyet           sakınca            yeşil             apse   \n",
       "5            yürekli             sapık       şövalyelik         kasvetli   \n",
       "6               maaş  anayasaya aykırı       kozmopolit   kabul edilemez   \n",
       "7            tutkulu              yama         Bilişsel       şanssızlık   \n",
       "8           çikolata         karartmak        ağırbaşlı          kovulma   \n",
       "9           canlanma          aptallık            temiz           düşmek   \n",
       "10           mübarek             maruz     telafi edici           kitabe   \n",
       "11        gıdıklamak             hariç            bayım           kolera   \n",
       "12             aloha       körü körüne          sıkılık           çürüme   \n",
       "13            Gökler             Alarm            atlet         saygısız   \n",
       "14        özgürleşme              apse         eleştiri             dava   \n",
       "15           Bulunan             tütsü         özgürlük            eksik   \n",
       "16             tatil        hoşlanmama           macera           kürtaj   \n",
       "17            armoni       yetki devri         mütevazi     ölüme mahkum   \n",
       "18           otantik          kasvetli       kooperatif           soymak   \n",
       "19          büyüklük              sade          tanıtım          tükenme   \n",
       "20          torunlar    kabul edilemez         muzaffer           hırsız   \n",
       "21    güzelleştirmek        şanssızlık            nimet        demirleme   \n",
       "22           gönüllü           kovulma          örgütlü  şekil bozukluğu   \n",
       "23            mucize            öfkeli             kaya        çukurluğu   \n",
       "24              vefa            düşmek        mezuniyet            iblis   \n",
       "25          kalkınan             günah          yorumcu        dökümleri   \n",
       "26            favori               pus          yürekli       eşitsizlik   \n",
       "27          Sevgilim           antitez        demirleme          ızdırap   \n",
       "28             oynak            kolera         bütünlük       kilitlenme   \n",
       "29             flört        forewarned     dayanma gücü          ağrıyan   \n",
       "...              ...               ...              ...              ...   \n",
       "1593             NaN      adaletsizlik              NaN              NaN   \n",
       "1594             NaN            bitkin              NaN              NaN   \n",
       "1595             NaN        kıpırdamak              NaN              NaN   \n",
       "1596             NaN      karmakarışık              NaN              NaN   \n",
       "1597             NaN   dikkat dağıtıcı              NaN              NaN   \n",
       "1598             NaN             inkâr              NaN              NaN   \n",
       "1599             NaN        kamçılamak              NaN              NaN   \n",
       "1600             NaN             tezat              NaN              NaN   \n",
       "1601             NaN         durgunluk              NaN              NaN   \n",
       "1602             NaN           gecikme              NaN              NaN   \n",
       "1603             NaN            bağnaz              NaN              NaN   \n",
       "1604             NaN           korkmuş              NaN              NaN   \n",
       "1605             NaN            kurban              NaN              NaN   \n",
       "1606             NaN         kandırmak              NaN              NaN   \n",
       "1607             NaN         hırsızlık              NaN              NaN   \n",
       "1608             NaN     modası geçmiş              NaN              NaN   \n",
       "1609             NaN               Ruh              NaN              NaN   \n",
       "1610             NaN              yaya              NaN              NaN   \n",
       "1611             NaN           ağlamak              NaN              NaN   \n",
       "1612             NaN           kurtçuk              NaN              NaN   \n",
       "1613             NaN             emmek              NaN              NaN   \n",
       "1614             NaN            drenaj              NaN              NaN   \n",
       "1615             NaN     acı çektirmek              NaN              NaN   \n",
       "1616             NaN          kesilmiş              NaN              NaN   \n",
       "1617             NaN          düzenbaz              NaN              NaN   \n",
       "1618             NaN             Çürük              NaN              NaN   \n",
       "1619             NaN            boykot              NaN              NaN   \n",
       "1620             NaN              imha              NaN              NaN   \n",
       "1621             NaN    Güvenlik açığı              NaN              NaN   \n",
       "1622             NaN           pısırık              NaN              NaN   \n",
       "\n",
       "                    8                9  \n",
       "0     ortaya çıkarmak         haysiyet  \n",
       "1              mistik  dayanak noktası  \n",
       "2               Alarm          faydalı  \n",
       "3            özgürlük            yeşil  \n",
       "4                dava             sade  \n",
       "5           mezuniyet       kozmopolit  \n",
       "6              hırsız            bayım  \n",
       "7            kararsız          sıkılık  \n",
       "8          kilitlenme         özgürlük  \n",
       "9                 pop          holding  \n",
       "10           sarsıntı         mütevazi  \n",
       "11          kaybetmek             iman  \n",
       "12         gıdıklamak          gösteri  \n",
       "13           büyüklük       kooperatif  \n",
       "14             mucize             yuva  \n",
       "15          istemeden     reddediyoruz  \n",
       "16     hava saldırısı            kayıt  \n",
       "17              oynak        mezuniyet  \n",
       "18              flört          yürekli  \n",
       "19           susuzluk         bütünlük  \n",
       "20               peri            polis  \n",
       "21          alışveriş            kanıt  \n",
       "22      tamamlayıcısı     dayanma gücü  \n",
       "23             uyardı            masum  \n",
       "24              coşku        hakimiyet  \n",
       "25            sırıtış               at  \n",
       "26              akrep            sabır  \n",
       "27               çile             maaş  \n",
       "28           nimetler          analist  \n",
       "29                hoş          tutkulu  \n",
       "...               ...              ...  \n",
       "1593              NaN              NaN  \n",
       "1594              NaN              NaN  \n",
       "1595              NaN              NaN  \n",
       "1596              NaN              NaN  \n",
       "1597              NaN              NaN  \n",
       "1598              NaN              NaN  \n",
       "1599              NaN              NaN  \n",
       "1600              NaN              NaN  \n",
       "1601              NaN              NaN  \n",
       "1602              NaN              NaN  \n",
       "1603              NaN              NaN  \n",
       "1604              NaN              NaN  \n",
       "1605              NaN              NaN  \n",
       "1606              NaN              NaN  \n",
       "1607              NaN              NaN  \n",
       "1608              NaN              NaN  \n",
       "1609              NaN              NaN  \n",
       "1610              NaN              NaN  \n",
       "1611              NaN              NaN  \n",
       "1612              NaN              NaN  \n",
       "1613              NaN              NaN  \n",
       "1614              NaN              NaN  \n",
       "1615              NaN              NaN  \n",
       "1616              NaN              NaN  \n",
       "1617              NaN              NaN  \n",
       "1618              NaN              NaN  \n",
       "1619              NaN              NaN  \n",
       "1620              NaN              NaN  \n",
       "1621              NaN              NaN  \n",
       "1622              NaN              NaN  \n",
       "\n",
       "[1623 rows x 10 columns]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon_df.to_csv('NRCLexicon/turkish_nrc.csv',index=False)\n",
    "lexicon_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lexicon_df = pd.read_csv('NRCLexicon/turkish_nrc.csv',encoding='ISO-8859-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading Word2Vec\n"
     ]
    }
   ],
   "source": [
    "###### STEP 3: Loading Word2Vec Model:\n",
    "#print (\"Loading Word2Vec\")\n",
    "#from gensim.models import word2vec\n",
    "#model = word2vec.Word2Vec.load('../../Project_Backup/BigData/Models/whole_it_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'insulto'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-82-facc477c30c1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'insulto'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'pirata'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\fnac\\Anaconda3\\lib\\site-packages\\gensim\\models\\word2vec.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m   1387\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1388\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1389\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwv\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msimilarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mw2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1390\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m   1391\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fnac\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36msimilarity\u001b[0;34m(self, w1, w2)\u001b[0m\n\u001b[1;32m    366\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    367\u001b[0m         \"\"\"\n\u001b[0;32m--> 368\u001b[0;31m         \u001b[1;32mreturn\u001b[0m \u001b[0mdot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmatutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0munitvec\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mw2\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    369\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    370\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mn_similarity\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mws2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mC:\\Users\\fnac\\Anaconda3\\lib\\site-packages\\gensim\\models\\keyedvectors.py\u001b[0m in \u001b[0;36m__getitem__\u001b[0;34m(self, words)\u001b[0m\n\u001b[1;32m    346\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstring_types\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    347\u001b[0m             \u001b[1;31m# allow calls like trained_model['office'], as a shorthand for trained_model[['office']]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m--> 348\u001b[0;31m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    349\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m    350\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mvstack\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msyn0\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mword\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mindex\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mword\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mwords\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 'insulto'"
     ]
    }
   ],
   "source": [
    "model.similarity('insulto','pirata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def compute_matrix_sentences_list_word2vec(nava_words, nrc_lexicon,model):\n",
    "    \"\"\"\n",
    "\n",
    "    :param word2vec model:\n",
    "    :param nava_words: we can pass any version of the bag of words\n",
    "    :param nrc_lexicon:\n",
    "    :return:\n",
    "    \"\"\"\n",
    "\n",
    "    sm_list = list_nrc_lexicon(nrc_lexicon)\n",
    "    emotions = nrc_lexicon.columns.values\n",
    "    matrix_sentences_list = []\n",
    "    for i in tqdm(range(0, len(nava_words))): # Iterate over all sentences\n",
    "        \" Initialize matrix for each sentence \"\n",
    "        w, h = len(nava_words[i]), 10\n",
    "        matrix_sentence = [[0 for x in range(w)] for y in range(h)]\n",
    "        k = 0\n",
    "        for word in nava_words[i]: # Iterate over all words in the sentence\n",
    "            j = 0\n",
    "            for emotion in range(0, len(emotions)): # Iterate over all emotions => fill in the emotional vectors for all words\n",
    "                total_similarity = 0\n",
    "                for representative_word in sm_list[emotion][0:10]:\n",
    "                    r = len(sm_list[emotion])\n",
    "                    if word in model and representative_word in model:\n",
    "                        total_similarity += model.similarity(word, representative_word)\n",
    "                matrix_sentence[j][k] += total_similarity / r \n",
    "                j += 1 # increment index of representative words\n",
    "            k += 1 # increment index of transcript words\n",
    "        # append the matrix_sentence to the global list for all sentences\n",
    "        matrix_sentences_list.append(matrix_sentence)\n",
    "    return matrix_sentences_list\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hb']"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nava_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing word level scores\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|█████████████████████████████████| 331035/331035 [44:36<00:00, 123.66it/s]\n"
     ]
    }
   ],
   "source": [
    "###### STEP 4: Word Level\n",
    "print (\"Computing word level scores\")\n",
    "matrix_sentences_word2vec = compute_matrix_sentences_list_word2vec(nava_tweets,lexicon_df,model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0057116875423981039, 0.0078047429297374085],\n",
       " [0.0060167928180368145, 0.01023575849751735],\n",
       " [0.0061844762299235389, 0.0093637660441997748],\n",
       " [0.0029643438294465266, 0.0043628413126492243],\n",
       " [0.010222436134512642, 0.016063174154950687],\n",
       " [0.0021053958348313797, 0.0035463607810704862],\n",
       " [0.0020871663320264386, 0.003241831617149262],\n",
       " [0.0039944016485211065, 0.0063264527756776373],\n",
       " [0.013639043814702283, 0.020052841149304629],\n",
       " [0.0058338785292868529, 0.0087626098500389483]]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sentences_word2vec[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['hb']"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nava_tweets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from __future__ import division\n",
    "\n",
    "def compute_sentence_emotion_vectors(matrix_sentences_list):\n",
    "    emotion_vector_list = []\n",
    "    for i in tqdm(range(0, len(matrix_sentences_list))):\n",
    "        sum_sentence = []\n",
    "        ids = [0,1,2,3,4,7,8,9]\n",
    "        for j in ids: # for each emotion\n",
    "            sum_words = 0\n",
    "            for k in range(0, len(matrix_sentences_list[i][j])):\n",
    "                sum_words += matrix_sentences_list[i][j][k]*1000\n",
    "            r = len(matrix_sentences_list[i])\n",
    "            if r != 0 :\n",
    "                sum_words = sum_words / r # Arithmetic mean\n",
    "            sum_sentence.append(sum_words)\n",
    "        emotion_vector_list.append(sum_sentence)\n",
    "    return emotion_vector_list\n",
    "\n",
    "def compute_sentence_sentiment_vectors(matrix_sentences_list):\n",
    "    emotion_vector_list = []\n",
    "    for i in tqdm(range(0, len(matrix_sentences_list))):\n",
    "        sum_sentence = []\n",
    "        ids = [5,6]\n",
    "        for j in ids: # for each emotion\n",
    "            sum_words = 0\n",
    "            for k in range(0, len(matrix_sentences_list[i][j])):\n",
    "                sum_words += matrix_sentences_list[i][j][k]*1000\n",
    "            r = len(matrix_sentences_list[i])\n",
    "            if r != 0 : \n",
    "                sum_words = sum_words / r\n",
    "            sum_sentence.append(sum_words)\n",
    "        emotion_vector_list.append(sum_sentence)\n",
    "    return emotion_vector_list\n",
    "\n",
    "def compute_emotionalities(sentence_vectors):\n",
    "    emotionalities = []\n",
    "    threshold = 0 # THRESHOLD PARAMETER TO BE FINE TUNED (0 for lexicon, 0.2 for pmi)\n",
    "    for i in tqdm(range(0,len(sentence_vectors))):\n",
    "        sentence_vector = sentence_vectors[i]\n",
    "        mylist = [0 if math.isnan(x) else x for x in sentence_vector]\n",
    "        if (max(mylist) > threshold): #Threshold \n",
    "            emotionalities.append(sentence_vectors[i].index(max(mylist)))\n",
    "        else: \n",
    "            emotionalities.append(8)\n",
    "    return emotionalities\n",
    "\n",
    "def compute_sentiments(sentence_vectors_sent,emotionalities):\n",
    "    sentiments = []\n",
    "    threshold = 0 # THRESHOLD PARAMETER TO BE FINE TUNED (0 for lexicon, 0.2 for pmi)\n",
    "    for i in tqdm(range(0,len(sentence_vectors_sent))):\n",
    "        sentence_vector = sentence_vectors_sent[i]\n",
    "        mylist = [0 if math.isnan(x) else x for x in sentence_vector]\n",
    "        if (max(mylist) > threshold): #Threshold \n",
    "            sentiments.append(sentence_vectors_sent[i].index(max(mylist)))\n",
    "        else:\n",
    "            # To increase Recall, we also use emotionalities, in case a tweet is neutral\n",
    "            if emotionalities[i] in [0,2,3,5]:\n",
    "                sentiments.append(0) # Negative Emotion\n",
    "            if emotionalities[i] in [1,4,6,7]:\n",
    "                sentiments.append(1) # Positive Emotion\n",
    "            if emotionalities[i] == 8:\n",
    "                sentiments.append(2) # Otherwise, we just return Neutral\n",
    "    return sentiments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing Emotionalities\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████| 331035/331035 [00:13<00:00, 24900.24it/s]\n",
      "100%|██████████████████████████████| 331035/331035 [00:01<00:00, 293812.79it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Computing sentiments\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████| 331035/331035 [00:03<00:00, 101289.75it/s]\n",
      "100%|██████████████████████████████| 331035/331035 [00:00<00:00, 484557.23it/s]\n"
     ]
    }
   ],
   "source": [
    "###### STEP 5: Sentence Level:\n",
    "print (\"Computing Emotionalities\")\n",
    "# Emotion Recognition\n",
    "sentence_vectors_word2vec = compute_sentence_emotion_vectors(matrix_sentences_word2vec)\n",
    "\n",
    "emotionalities = compute_emotionalities(sentence_vectors_word2vec)\n",
    "\n",
    "\n",
    "# Sentiment Analysis\n",
    "print (\"Computing sentiments\")\n",
    "sentence_vectors_sent = compute_sentence_sentiment_vectors(matrix_sentences_word2vec)\n",
    "\n",
    "sentiments = compute_sentiments(sentence_vectors_sent,emotionalities)\n",
    "\n",
    "###### FINAL STEP 6: Storing Emotion + Sentiment for each tweet\n",
    "\n",
    "emo_dict = {\n",
    "    0: 'Anger',\n",
    "    1: 'Anticipation',\n",
    "    2: 'Disgust',\n",
    "    3: 'Fear',\n",
    "    4: 'Joy',\n",
    "    5: 'Sadness',\n",
    "    6: 'Surprise',\n",
    "    7: 'Trust',\n",
    "    8: 'Neutral'\n",
    "}\n",
    "sent_dict = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\"\n",
    "}\n",
    "\n",
    "emotions = []\n",
    "senti = []\n",
    "for i in range(0,len(emotionalities)):\n",
    "    emotions.append(emo_dict[emotionalities[i]])\n",
    "    senti.append(sent_dict[sentiments[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1.4284738775261361,\n",
       " 1.9759870158033888,\n",
       " 1.7182788249045373,\n",
       " 0.74582752934429064,\n",
       " 3.1997340641994776,\n",
       " 1.08907041512743,\n",
       " 3.839270773118701,\n",
       " 1.6812337177804835]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors_word2vec[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Storing in dataframe\n"
     ]
    }
   ],
   "source": [
    "print (\"Storing in dataframe\")\n",
    "word2vec_results_df = pd.DataFrame()\n",
    "\n",
    "word2vec_results_df['Nava Tweet'] = nava_tweets\n",
    "\n",
    "word2vec_results_df['Emotion Vectors'] = sentence_vectors_word2vec\n",
    "\n",
    "word2vec_results_df['Emotion'] = emotions\n",
    "\n",
    "word2vec_results_df['Sentiment Vectors'] = sentence_vectors_sent\n",
    "\n",
    "word2vec_results_df['Sentiment'] = senti\n",
    "\n",
    "word2vec_results_df.to_csv('../../Project_Backup/BigData/Word2VecBasedResults/tr/Tweets_Labelled_Word2Vec.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Nava Tweet</th>\n",
       "      <th>Emotion Vectors</th>\n",
       "      <th>Emotion</th>\n",
       "      <th>Sentiment Vectors</th>\n",
       "      <th>Sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[iphoon, meten, nexus]</td>\n",
       "      <td>[0.884920438723, 2.30446919141, 1.0439055915, ...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>[0.260638537939, 0.354363314745]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[beginning, feel, home, eten, hangkant]</td>\n",
       "      <td>[1.23918403443, 2.73380914632, 1.25902353457, ...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>[0.310734460599, 0.3274642242]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[ueeeeeeeeeeeeeooo]</td>\n",
       "      <td>[0.0674638401601, 0.135911464138, 0.0636923252...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>[0.0186801057148, 0.0133107461327]</td>\n",
       "      <td>Positive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[arzurich, developer, designer, geotaggers, al...</td>\n",
       "      <td>[3.67700226412, 8.89141266243, 4.24250307971, ...</td>\n",
       "      <td>Surprise</td>\n",
       "      <td>[1.0491679129, 1.30976516478]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[tapas, et, hoegaard, joli, apéro, chez, mathi...</td>\n",
       "      <td>[1.14908027863, 3.52168975666, 1.09623750354, ...</td>\n",
       "      <td>Joy</td>\n",
       "      <td>[0.42267562281, 0.566264562012]</td>\n",
       "      <td>Negative</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          Nava Tweet  \\\n",
       "0                             [iphoon, meten, nexus]   \n",
       "1            [beginning, feel, home, eten, hangkant]   \n",
       "2                                [ueeeeeeeeeeeeeooo]   \n",
       "3  [arzurich, developer, designer, geotaggers, al...   \n",
       "4  [tapas, et, hoegaard, joli, apéro, chez, mathi...   \n",
       "\n",
       "                                     Emotion Vectors   Emotion  \\\n",
       "0  [0.884920438723, 2.30446919141, 1.0439055915, ...  Surprise   \n",
       "1  [1.23918403443, 2.73380914632, 1.25902353457, ...  Surprise   \n",
       "2  [0.0674638401601, 0.135911464138, 0.0636923252...  Surprise   \n",
       "3  [3.67700226412, 8.89141266243, 4.24250307971, ...  Surprise   \n",
       "4  [1.14908027863, 3.52168975666, 1.09623750354, ...       Joy   \n",
       "\n",
       "                    Sentiment Vectors Sentiment  \n",
       "0    [0.260638537939, 0.354363314745]  Negative  \n",
       "1      [0.310734460599, 0.3274642242]  Negative  \n",
       "2  [0.0186801057148, 0.0133107461327]  Positive  \n",
       "3       [1.0491679129, 1.30976516478]  Negative  \n",
       "4     [0.42267562281, 0.566264562012]  Negative  "
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word2vec_results_df.head()"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
