{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "No module named 'spacy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-e90073f872fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mEmotionAnalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentSemanticModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mEmotionAnalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentTweetModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[1;32mfrom\u001b[0m \u001b[0mEmotionAnalysis\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSentSyntacticModule\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[1;33m*\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32mC:\\Users\\fnac\\Fall 2016\\ADA\\Project\\GMR_ADA_Project\\EmotionAnalysis\\SentSyntacticModule.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[1;32mimport\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0mspacy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msymbols\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mnsubj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0madvmod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0macomp\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mamod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mneg\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mNOUN\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mVERB\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mADJ\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mADV\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0mapply_syntactic_rules\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdocs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mnew_samples\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mtriple_dependencies\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: No module named 'spacy'"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import ast\n",
    "import pickle\n",
    "from EmotionAnalysis.DataSchemaExtractionParsing import *\n",
    "from EmotionAnalysis.DataPreProcessing import *\n",
    "from EmotionAnalysis.SentSemanticModule import *\n",
    "from EmotionAnalysis.SentTweetModule import *\n",
    "from EmotionAnalysis.SentSyntacticModule import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('NRCLexicon/portuguese_lexicon.pickle', 'rb') as handle:\n",
    "    lexicon_dict = pickle.load(handle)\n",
    "len(lexicon_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Rule-Based Lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meryem/miniconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "###### STEP 1: Loading Data with tokenized and affective representation:\n",
    "# HERE YOU CAN CHANGE THE NAME OF THE FILE FROM WHICH TO LOAD THE DATA\n",
    "\n",
    "tweets_df = pd.read_csv('/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/Results/Test/Unannotated_Representation.csv')\n",
    "\n",
    "nava_repr = tweets_df['Nava Representation'] \n",
    "\n",
    "# Convert nava_tweets \n",
    "nava_tweets = []\n",
    "for i in range(0, len(nava_repr)):\n",
    "    result = ast.literal_eval(nava_repr[i])\n",
    "    nava_tweets.append(result)\n",
    "\n",
    "\n",
    "###### STEP 2: Loading Lexicon:\n",
    "lexicon_df = pd.read_csv('/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/NRCLexicon/lexicon_nrc.csv',encoding='utf-8')\n",
    "unique_lexicon = make_unique_lexicon(lexicon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_sentences_lexicon = compute_matrix_sentences_list_lexicon(nava_tweets[365:366],lexicon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [0], [1], [0], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sentences_lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors_lexicon = compute_sentence_emotion_vectors(matrix_sentences_lexicon)\n",
    "sentence_vectors_lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotionalities = compute_emotionalities(sentence_vectors_lexicon)\n",
    "\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentence_vectors_sent = compute_sentence_sentiment_vectors(matrix_sentences_lexicon)\n",
    "\n",
    "sentiments = compute_sentiments(sentence_vectors_sent,emotionalities)\n",
    "\n",
    "###### FINAL STEP 5: Storing Emotion + Sentiment for each tweet\n",
    "\n",
    "emo_dict = {\n",
    "    0: 'Anger',\n",
    "    1: 'Anticipation',\n",
    "    2: 'Disgust',\n",
    "    3: 'Fear',\n",
    "    4: 'Joy',\n",
    "    5: 'Sadness',\n",
    "    6: 'Surprise',\n",
    "    7: 'Trust',\n",
    "    8: 'Neutral'\n",
    "}\n",
    "sent_dict = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
