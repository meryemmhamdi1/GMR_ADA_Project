{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extracting and Preparing Lexicons:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['English Word', 'Arabic Translation (Google Translate)',\n",
       "       'Basque Translation (Google Translate)',\n",
       "       'Bengali Translation (Google Translate)',\n",
       "       'Catalan Translation (Google Translate)',\n",
       "       'Chinese (simplified) Translation (Google Translate)',\n",
       "       'Chinese (traditional) Translation (Google Translate)',\n",
       "       'Danish Translation (Google Translate)',\n",
       "       'Dutch Translation (Google Translate)',\n",
       "       'Esperanto Translation (Google Translate)',\n",
       "       'Finnish Translation (Google Translate)',\n",
       "       'French Translation (Google Translate)',\n",
       "       'German Translation (Google Translate)',\n",
       "       'Greek Translation (Google Translate)',\n",
       "       'Gujarati Translation (Google Translate)',\n",
       "       'Hebrew Translation (Google Translate)',\n",
       "       'Hindi Translation (Google Translate)',\n",
       "       'Irish Translation (Google Translate)',\n",
       "       'Italian Translation (Google Translate)',\n",
       "       'Japanese Translation (Google Translate)',\n",
       "       'Latin Translation (Google Translate)',\n",
       "       'Marathi Translation (Google Translate)',\n",
       "       'Persian Translation (Google Translate)',\n",
       "       'Portuguese Translation (Google Translate)',\n",
       "       'Romanian Translation (Google Translate)',\n",
       "       'Russian Translation (Google Translate)',\n",
       "       'Somali Translation (Google Translate)',\n",
       "       'Spanish Translation (Google Translate)',\n",
       "       'Sudanese Translation (Google Translate)',\n",
       "       'Swahili Translation (Google Translate)',\n",
       "       'Swedish Translation (Google Translate)',\n",
       "       'Tamil Translation (Google Translate)',\n",
       "       'Telugu Translation (Google Translate)',\n",
       "       'Thai Translation (Google Translate)',\n",
       "       'Turkish Translation (Google Translate)',\n",
       "       'Ukranian Translation (Google Translate)',\n",
       "       'Urdu Translation (Google Translate)',\n",
       "       'Vietnamese Translation (Google Translate)',\n",
       "       'Welsh Translation (Google Translate)',\n",
       "       'Yiddish Translation (Google Translate)',\n",
       "       'Zulu Translation (Google Translate)', 'Positive', 'Negative', 'Anger',\n",
       "       'Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise',\n",
       "       'Trust'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lexicon.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'lexicon' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-c350df24369d>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[1;31m#lexicon['Score'] = lexicon['col'].str.split().apply(lambda x: x[-1])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[1;31m#del (lexicon['col'])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mfrench_lexicon\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlexicon\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'French Translation (Google Translate)'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Positive'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Negative'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Anger'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Anticipation'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Disgust'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Fear'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Joy'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Sadness'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'Surprise'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;34m'Trust'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mfrench_lexicon\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mhead\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'lexicon' is not defined"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "#lexicon = pd.read_excel('NRCLexicon/NRC-Emotion-Lexicon-v0.92-InManyLanguages-web.xlsx')\n",
    "#lexicon['Word'] = lexicon['col'].str.split().apply(lambda x: x[0])\n",
    "#lexicon['EmotionCategory'] = lexicon['col'].str.split().apply(lambda x: x[1])\n",
    "#lexicon['Score'] = lexicon['col'].str.split().apply(lambda x: x[-1])\n",
    "#del (lexicon['col'])\n",
    "french_lexicon = lexicon[['French Translation (Google Translate)','Positive', 'Negative','Anger','Anticipation', 'Disgust', 'Fear', 'Joy', 'Sadness', 'Surprise','Trust']]\n",
    "french_lexicon.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "d = {}\n",
    "for i in range(0,len(french_lexicon)):\n",
    "    d[french_lexicon.iloc[i]['Turkish Translation (Google Translate)']] = [french_lexicon.iloc[i]['Anger'],french_lexicon.iloc[i]['Anticipation'], french_lexicon.iloc[i]['Disgust'], french_lexicon.iloc[i]['Fear'], french_lexicon.iloc[i]['Joy'],french_lexicon.iloc[i]['Negative'],french_lexicon.iloc[i]['Positive'], french_lexicon.iloc[i]['Sadness'], french_lexicon.iloc[i]['Surprise'],french_lexicon.iloc[i]['Trust']]\n",
    "\n",
    "d = {k: v for k, v in d.items() if v !=[0,0,0,0,0,0,0,0,0,0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6468"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "\n",
    "with open('NRCLexicon/english_lexicon.pickle', 'wb') as handle:\n",
    "    pickle.dump(d, handle, protocol=2)\n",
    "\n",
    "with open('NRCLexicon/english_lexicon.pickle', 'rb') as handle:\n",
    "    b = pickle.load(handle)\n",
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5100"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pickle\n",
    "with open('NRCLexicon/portuguese_lexicon.pickle', 'rb') as handle:\n",
    "    lexicon_dict = pickle.load(handle)\n",
    "len(lexicon_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3500272"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "fr_data = pd.read_csv('C:/Users/fnac/Downloads/fr.csv',encoding='utf-8')\n",
    "len(fr_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "451425"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fr_data1 = fr_data[1048575:1500000][['text']]\n",
    "fr_data1.to_csv('C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr_1.csv',encoding='utf-8')\n",
    "fr_data2 = fr_data[1500000:2000000][['text']]\n",
    "fr_data2.to_csv('C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr_2.csv',encoding='utf-8')\n",
    "fr_data3 = fr_data[2000000:2500000][['text']]\n",
    "fr_data3.to_csv('C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr_3.csv',encoding='utf-8')\n",
    "fr_data4 = fr_data[2500000:3000000][['text']]\n",
    "fr_data4.to_csv('C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr_4.csv',encoding='utf-8')\n",
    "fr_data5 = fr_data[3000000:len(fr_data)][['text']]\n",
    "fr_data5.to_csv('C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr_5.csv',encoding='utf-8')\n",
    "len(fr_data1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "yes\n"
     ]
    }
   ],
   "source": [
    "if \"terk\" in b.keys():\n",
    "    print (\"yes\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "np.save('NRCLexicon/french_lexicon.npy',d)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'journée'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-46-d48ef2fb4012>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mload\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'french_lexicon.npy'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'journée'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m: 'journée'"
     ]
    }
   ],
   "source": [
    "np.load('french_lexicon.npy').item()['journée']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3242"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7224"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying Rule-Based Lexicon:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meryem/miniconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import sys\n",
    "sys.path.insert(0, \"/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/EmotionAnalysis\") \n",
    "from DataSchemaExtractionParsing import *\n",
    "from DataPreProcessing import *\n",
    "from SentSemanticModule import *\n",
    "from SentTweetModule import *\n",
    "from SentSyntacticModule import *\n",
    "import ast\n",
    "\n",
    "###### STEP 1: Loading Data with tokenized and affective representation:\n",
    "# HERE YOU CAN CHANGE THE NAME OF THE FILE FROM WHICH TO LOAD THE DATA\n",
    "\n",
    "tweets_df = pd.read_csv('/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/Results/Test/Unannotated_Representation.csv')\n",
    "\n",
    "nava_repr = tweets_df['Nava Representation'] \n",
    "\n",
    "# Convert nava_tweets \n",
    "nava_tweets = []\n",
    "for i in range(0, len(nava_repr)):\n",
    "    result = ast.literal_eval(nava_repr[i])\n",
    "    nava_tweets.append(result)\n",
    "\n",
    "\n",
    "###### STEP 2: Loading Lexicon:\n",
    "lexicon_df = pd.read_csv('/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/NRCLexicon/lexicon_nrc.csv',encoding='utf-8')\n",
    "unique_lexicon = make_unique_lexicon(lexicon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "matrix_sentences_lexicon = compute_matrix_sentences_list_lexicon(nava_tweets[365:366],lexicon_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0], [1], [0], [0], [1], [0], [1], [0], [0], [1]]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_sentences_lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence_vectors_lexicon = compute_sentence_emotion_vectors(matrix_sentences_lexicon)\n",
    "sentence_vectors_lexicon[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "emotionalities = compute_emotionalities(sentence_vectors_lexicon)\n",
    "\n",
    "\n",
    "# Sentiment Analysis\n",
    "sentence_vectors_sent = compute_sentence_sentiment_vectors(matrix_sentences_lexicon)\n",
    "\n",
    "sentiments = compute_sentiments(sentence_vectors_sent,emotionalities)\n",
    "\n",
    "###### FINAL STEP 5: Storing Emotion + Sentiment for each tweet\n",
    "\n",
    "emo_dict = {\n",
    "    0: 'Anger',\n",
    "    1: 'Anticipation',\n",
    "    2: 'Disgust',\n",
    "    3: 'Fear',\n",
    "    4: 'Joy',\n",
    "    5: 'Sadness',\n",
    "    6: 'Surprise',\n",
    "    7: 'Trust',\n",
    "    8: 'Neutral'\n",
    "}\n",
    "sent_dict = {\n",
    "    0: \"Negative\",\n",
    "    1: \"Positive\",\n",
    "    2: \"Neutral\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentiments[0]"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
