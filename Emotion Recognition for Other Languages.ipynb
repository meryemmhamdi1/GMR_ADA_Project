{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/meryem/miniconda2/lib/python2.7/site-packages/gensim/utils.py:1015: UserWarning: Pattern library is not installed, lemmatization won't be available.\n",
      "  warnings.warn(\"Pattern library is not installed, lemmatization won't be available.\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd \n",
    "import sys\n",
    "sys.path.insert(0, \"/media/diskD/EPFL/Fall 2016/ADA/Project/GMR_ADA_Project/EmotionAnalysis\") \n",
    "from DataSchemaExtractionParsing import *\n",
    "from DataPreProcessing import *\n",
    "from SentSemanticModule import *\n",
    "from SentTweetModule import *\n",
    "from SentSyntacticModule import *\n",
    "\n",
    "pd.set_option('display.max_rows', 500)\n",
    "pd.set_option('display.max_columns', 500)\n",
    "pd.set_option('display.max_colwidth', 500)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                   Petit -13 degrés ce soir... (@ La Fouly) http://4sq.com/duzb1D\n",
       "1                                 #café — at Café la Source http://gowal.la/s/2DFB\n",
       "2           Champions League: \"Real Madrid - Olympique Lyonnais\" auf HD Suisse #fb\n",
       "3                                        @Pizzle_14 yeah, je géotaggue a Neuchâtel\n",
       "4    @mb_4 j'ai retrouver JP mais il c'est coupé le tiff http://twitpic.com/18bawq\n",
       "5                           fontself.com est live. Félicitations à toute l'équipe.\n",
       "6            @Pi_XIV @jeremy_iv Jay toujours la pour faire le gag qu'il faut pas..\n",
       "7                                Apéro  — at Chateau Gütsch http://gowal.la/s/4Sui\n",
       "8              Repas en équipe, 1er tour de playoffs: ok! http://yfrog.com/6wz20fj\n",
       "9                         @jeremy_IV @skywalk_07 @pi_xiv ou une machine à laver...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_tweets = pd.read_csv('Data/fr_sample.csv')\n",
    "french_tweets['text'].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "replaced_categories = handle_special_categories(french_tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tokenized_list = bag_of_word_representation(replaced_categories)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Petit', 'degrs', 'ce', 'soir', 'La', 'Fouly']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fontself', 'NN'),\n",
       " ('com', 'NN'),\n",
       " ('est', 'RB'),\n",
       " ('live', 'JJ'),\n",
       " ('Flicitations', 'NNP'),\n",
       " ('toute', 'NN'),\n",
       " ('l', 'NN'),\n",
       " ('quipe', 'NN')]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tagged_tweets = pos_tagging(tokenized_list)\n",
    "tagged_tweets[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "# de, ar, it, pt\n",
    "#C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData\n",
    "tweets = pd.read_csv(\"C:/Users/fnac/Downloads/pt.csv\", encoding =\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tweets = tweets[['text']]\n",
    "tweets.to_csv(\"C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/pt.csv\", encoding =\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1048575"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets = pd.read_csv(\"C:/Users/fnac/Fall 2016/ADA/Project_Backup/BigData/RawData/fr.csv\", encoding =\"utf-8\")\n",
    "len(tweets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ[\"STANFORD_MODELS\"] = \"/home/meryem/Downloads/stanford-parser-full-2016-10-31\"\n",
    "os.environ[\"STANFORD_PARSER\"] = \"/home/meryem/Downloads/stanford-parser-full-2016-10-31\"\n",
    "from nltk.parse.stanford import StanfordDependencyParser\n",
    "dep_parser=StanfordDependencyParser(model_path=\"/home/meryem/Downloads/stanford-parser-full-2016-10-31/edu/stanford/nlp/models/lexparser/englishPCFG.ser.gz\")\n",
    "trees = [parse.tree() for parse in dep_parser.raw_parse(\"no i am not jealous\")\n",
    "dependency_trees = []\n",
    "result = dep_parser.raw_parse(\"no i am not jealous\")\n",
    "dep = result.next()\n",
    "dependency_trees.append(list(dep.triples())"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
